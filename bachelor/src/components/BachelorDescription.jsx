import React from 'react';
import DownloadButton from "../components/DownoadButton";

// Styles
import styles from "../styles/LoRaPage/LoRaPage.module.scss";
import iconStyles from "../styles/Footer.module.scss";
import smallStyles from "../styles/Icons.module.scss";

// Images
import autoencoder from "../assets/projects_img/autoencoder.png";
import encoder from "../assets/projects_img/encoder.png";
import decoder from "../assets/projects_img/decoder.png";
import barlow from "../assets/projects_img/barlow.png";

import scrum from '../assets/skills/scrum.svg'
import python from "../assets/skills/python.svg";
import tensorflow from "../assets/skills/tensorflow.svg";
import docker from "../assets/skills/docker.svg";
import jira from "../assets/skills/atlassian.svg";

const BachelorDescription = () => {
    return (
        <div className={`${styles.ourMissionBanner} context-wrapper bottom-divider-large`}>
            <div className={styles.missionContext}>
                <h1 className={`${styles.missionTitle} title-second`}>Autoencoder</h1>
                <p className={`${styles.missionText} text-main`}>The autoencoder model is a U-Net style architecture, characterized by an encoder, a latent space representation, and a decoder, is used to compress and decompress vector space. This model incorporates a binary hashing constraint as a convolutional layer substitute function in the encoder. </p>
                <img className={styles.missionImage} src={autoencoder} alt="" />
                <p className={`${styles.missionText} text-main`}>The encoder's input layer has a size of 128x128 pixels and a mode of three, indicating RGB channels. This choice of mode allows convolutional neural networks to learn separate representations of different color channels, enabling tasks such as edge detection and visual pattern recognition. The image size was set to 128x128 pixels with the intention of ensuring that the model can be trained on smaller datasets without requiring high computational resources. This design decision enables users with standard CPUs and GPUs to utilize the model effectively. </p>
                <br />
                
                <img className={styles.missionImage} src={encoder} alt="" />
                <br />
                <br />
                
                <h3 className={`${styles.missionTitle} title-second`}>Hashing layer</h3>
                <p className={`${styles.missionText} text-main`}>The hashing layer is constructed using the Conv2D class from Keras, which is an integrated library within TensorFlow. This layer is incorporated into the encoder, where it hashes the latent space representation, further compressing the output generated by the encoder. </p>
                <br />
                <br />
                <p className={`${styles.missionText} text-main`}>Similar to the encoder, the decoder also employs the ReLU activation function for its layers and includes skip connections between layers three and four. These skip connections help preserve information that might otherwise be lost during convolutions. The input size of the decoder matches the size of the latent space representation generated by the encoder. Additionally, the decoder outputs an image with the original dimensions of the input image to the neural network.</p>
                <br />
                
                <img className={styles.missionImage} src={decoder} alt="" />
                <br />
                <br />
                
                <h1 className={`${styles.storyTitle} title-second`}>Barlow Twins</h1>
                <p className={`${styles.missionText} text-main`}>The Barlow Twins model is utilised to validate the efficacy of the autoencoder, and hyperparamThe autoencoder model employs a U-Net style architecture, which consists of an encoder, a latent space representation, and a decoder.</p>
                <br/>
                <p className={`${styles.storyText} text-main`}>Its purpose is to compress and decompress vector space data. In the encoder section, a binary hashing constraint is integrated as a substitute function for convolutional layers. To assess the performance of the autoencoder, the Barlow Twins' model is utilized. Additionally, hyperparameter optimization is conducted using the Optuna software.eter optimization is achieved using the Optuna software.</p>
                <br />
                <img className={styles.missionImage} src={barlow} alt="" />
                <br />
                <br />
                
                <p className={`${styles.storyText} text-main`}>Download the full report for implementation details and to view the results. </p>
                <br />
                <DownloadButton />
                <br />
                <br /> 
                
            </div>
            <div className={`${styles.footerContext} context-wrapper`}>
                <section className={iconStyles.footerBottom}>
                    <p>Language, frameworks and tools</p>
                    <br />
                    <br/>
                        <div className={smallStyles.teamCard}>
                            <div className={smallStyles.cardTitle}>
                            <img src={scrum} alt="" />
                            <img src={python} alt="" />
                            <img src={docker} alt="" />
                            <img src={tensorflow} alt="" />
                            <img src={jira} alt="" />
                        </div>
                    </div>     
                </section>
            </div>   
        </div>
    );
}
 
export default BachelorDescription;